analyze and memorize my backend files don't explain just analyze


11. # server/app/dashboard/routes.py

from flask import request, g
from app.dashboard import dashboard_bp
from app.auth.middleware import require_auth
from app.responses import success_response, error_response
from app.dashboard.views import resolve_view, get_stats
from app.dashboard.service import serialize_links
from app.folders.system import get_system_folders
import logging

logger = logging.getLogger(__name__)

# Import home routes
from app.dashboard.home.routes import *

@dashboard_bp.route('/links', methods=['GET'])
@require_auth
def get_links():
    """Get links for My Files dashboard with enhanced filtering"""
    view = request.args.get('view', 'all')
    search = request.args.get('search')
    cursor = request.args.get('cursor')
    
    # System folder support
    system_folder = request.args.get('system_folder')
    folder_id = request.args.get('folder_id', type=int)
    tag_ids_str = request.args.get('tag_ids')
    unassigned_only = request.args.get('unassigned_only', 'false').lower() == 'true'
    
    # New filters
    starred_only = request.args.get('starred', 'false').lower() == 'true'
    pinned_only = request.args.get('pinned', 'false').lower() == 'true'
    link_type = request.args.get('link_type')
    
    tag_ids = []
    if tag_ids_str:
        try:
            tag_ids = [int(tid) for tid in tag_ids_str.split(',')]
        except ValueError:
            tag_ids = []

    try:
        limit = int(request.args.get('limit', 20))
    except (ValueError, TypeError):
        limit = 20

    links, next_cursor, meta = resolve_view(
        user_id=g.current_user.id,
        view=view,
        search=search,
        cursor=cursor,
        limit=limit,
        system_folder=system_folder,
        folder_id=folder_id,
        tag_ids=tag_ids,
        unassigned_only=unassigned_only,
        starred_only=starred_only,
        pinned_only=pinned_only,
        link_type=link_type,
    )

    return success_response({
        'links': serialize_links(links),
        'meta': meta,
    })

@dashboard_bp.route('/stats', methods=['GET'])
@require_auth
def stats():
    """Get enhanced dashboard stats"""
    stats_data = get_stats(g.current_user.id)
    
    # Add system folders
    stats_data['system_folders'] = get_system_folders(g.current_user.id)
    
    return success_response({'stats': stats_data})

@dashboard_bp.route('/structure', methods=['GET'])
@require_auth  
def get_structure():
    """Get complete dashboard structure (folders + system folders)"""
    from app.folders.tree import get_folder_tree
    from app.folders.system import get_system_folders
    
    user_folders = get_folder_tree(g.current_user.id, include_counts=True)
    system_folders = get_system_folders(g.current_user.id)
    
    return success_response({
        'system_folders': system_folders,
        'user_folders': user_folders
    })




12. # server/app/dashboard/home/service.py

from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from sqlalchemy import and_, or_, desc, func
from app.extensions import db
from app.models import Link, Folder
from app.utils.ranking import calculate_importance_score
from app.dashboard.service import serialize_link
from app.folders.service import serialize_folder
import logging

logger = logging.getLogger(__name__)

QUICK_ACCESS_LIMIT = 8
RECENT_LIMIT = 20

def get_quick_access(user_id: str) -> List[Dict[str, Any]]:
    """Get quick access items (starred/pinned links + pinned folders)"""
    items = []
    
    # Get pinned and starred links
    links = Link.query.filter(
        Link.user_id == user_id,
        Link.soft_deleted == False,
        Link.archived_at.is_(None),
        or_(Link.pinned == True, Link.starred == True)
    ).order_by(
        desc(Link.pinned),
        desc(Link.starred),
        desc(Link.frequently_used),
        desc(Link.updated_at)
    ).limit(QUICK_ACCESS_LIMIT - 2).all()  # Reserve slots for folders
    
    for link in links:
        items.append({
            'type': 'link',
            'item': serialize_link(link),
            'importance': calculate_importance_score(link)
        })
    
    # Get pinned folders
    folders = Folder.query.filter(
        Folder.user_id == user_id,
        Folder.soft_deleted == False,
        Folder.pinned == True
    ).order_by(desc(Folder.updated_at)).limit(2).all()
    
    for folder in folders:
        items.append({
            'type': 'folder',
            'item': serialize_folder(folder, include_counts=True),
            'importance': 100  # Folders get high base importance
        })
    
    # Sort by importance and limit
    items.sort(key=lambda x: x['importance'], reverse=True)
    return [item['item'] for item in items[:QUICK_ACCESS_LIMIT]]

def get_recent_activity(user_id: str) -> List[Dict[str, Any]]:
    """Get recent activity (opened, added, edited)"""
    cutoff = datetime.utcnow() - timedelta(days=7)
    
    # Recent links (added or updated)
    links = Link.query.filter(
        Link.user_id == user_id,
        Link.soft_deleted == False,
        Link.archived_at.is_(None),
        or_(
            Link.created_at >= cutoff,
            Link.updated_at >= cutoff
        )
    ).order_by(
        desc(Link.updated_at),
        desc(Link.created_at)
    ).limit(RECENT_LIMIT).all()
    
    items = []
    for link in links:
        activity_type = 'added' if link.created_at >= cutoff and link.updated_at <= link.created_at + timedelta(seconds=1) else 'edited'
        items.append({
            'type': 'link',
            'activity': activity_type,
            'timestamp': link.updated_at or link.created_at,
            'item': serialize_link(link)
        })
    
    # Sort by timestamp
    items.sort(key=lambda x: x['timestamp'], reverse=True)
    return items[:RECENT_LIMIT]

def mark_link_accessed(user_id: str, link_id: int) -> bool:
    """Mark a link as accessed for frequency tracking"""
    link = Link.query.filter_by(
        id=link_id,
        user_id=user_id,
        soft_deleted=False
    ).first()
    
    if not link:
        return False
    
    # Update access metrics
    link.click_count += 1
    link.updated_at = datetime.utcnow()
    
    # Mark as frequently used if accessed multiple times
    if link.click_count >= 3:
        link.frequently_used = True
    
    db.session.commit()
    return True

def get_home_stats(user_id: str) -> Dict[str, Any]:
    """Get quick stats for home dashboard"""
    # Total counts
    total_links = Link.query.filter(
        Link.user_id == user_id,
        Link.soft_deleted == False,
        Link.archived_at.is_(None)
    ).count()
    
    total_folders = Folder.query.filter(
        Folder.user_id == user_id,
        Folder.soft_deleted == False
    ).count()
    
    # This week's activity
    week_ago = datetime.utcnow() - timedelta(days=7)
    this_week = Link.query.filter(
        Link.user_id == user_id,
        Link.soft_deleted == False,
        Link.created_at >= week_ago
    ).count()
    
    return {
        'total_links': total_links,
        'total_folders': total_folders,
        'this_week': this_week
    }




13. # server/app/dashboard/home/routes.py

from flask import g
from app.dashboard import dashboard_bp
from app.auth.middleware import require_auth
from app.responses import success_response
from app.dashboard.home.service import (
    get_quick_access, get_recent_activity, get_home_stats
)

@dashboard_bp.route('/home/quick-access', methods=['GET'])
@require_auth
def home_quick_access():
    """Get quick access items for home dashboard"""
    items = get_quick_access(g.current_user.id)
    return success_response({'items': items})

@dashboard_bp.route('/home/recent', methods=['GET'])
@require_auth
def home_recent_activity():
    """Get recent activity for home dashboard"""
    activities = get_recent_activity(g.current_user.id)
    return success_response({'activities': activities})

@dashboard_bp.route('/home/stats', methods=['GET'])
@require_auth
def home_stats():
    """Get home dashboard stats"""
    stats = get_home_stats(g.current_user.id)
    return success_response({'stats': stats})




14. # server/app/folders/__init__.py
from flask import Blueprint

folders_bp = Blueprint('folders', __name__)

from . import routes




15. # server/app/folders/service.py

from datetime import datetime
from typing import Optional, List, Dict, Any, Tuple
from sqlalchemy import and_, func, desc
from app.extensions import db, redis_client
from app.models import Folder, Link
from app.utils.ordering import get_next_position
from app.folders.tree import get_folder_tree, move_folder
import logging
import json

logger = logging.getLogger(__name__)

class SmartFolderManager:
    """Intelligent folder management with auto-categorization"""
    
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.cache_key = f"folders:{user_id}"
    
    def create_smart_folder(self, data: Dict[str, Any]) -> Tuple[Optional[Folder], Optional[str]]:
        """Create folder with smart features"""
        name = data.get('name', '').strip()
        if not name:
            return None, 'Folder name is required'
        
        if len(name) > 255:
            return None, 'Folder name too long'
        
        # Check for existing folder
        existing = Folder.query.filter_by(
            user_id=self.user_id,
            name=name,
            soft_deleted=False,
            parent_id=data.get('parent_id')
        ).first()
        
        if existing:
            return None, 'Folder already exists'
        
        # Validate parent folder
        parent_id = data.get('parent_id')
        if parent_id:
            parent = Folder.query.filter_by(
                id=parent_id,
                user_id=self.user_id,
                soft_deleted=False
            ).first()
            
            if not parent:
                return None, 'Parent folder not found'
        
        # Auto-suggest folder properties
        suggested_props = self._suggest_folder_properties(name)
        
        folder = Folder(
            user_id=self.user_id,
            parent_id=parent_id,
            name=name,
            color=data.get('color') or suggested_props.get('color'),
            icon=data.get('icon') or suggested_props.get('icon'),
            position=get_next_position(Folder, self.user_id),
            pinned=data.get('pinned', False)
        )
        
        db.session.add(folder)
        db.session.commit()
        
        # Auto-categorize existing links
        if data.get('auto_categorize', False):
            self._auto_categorize_links(folder, name)
        
        # Clear cache
        self._clear_cache()
        
        return folder, None
    
    def _suggest_folder_properties(self, name: str) -> Dict[str, Any]:
        """Suggest color and icon based on folder name"""
        name_lower = name.lower()
        
        # Predefined mappings
        mappings = {
            'work': {'color': '#3B82F6', 'icon': 'briefcase'},
            'personal': {'color': '#10B981', 'icon': 'user'},
            'projects': {'color': '#F59E0B', 'icon': 'folder-open'},
            'research': {'color': '#8B5CF6', 'icon': 'academic-cap'},
            'tools': {'color': '#EF4444', 'icon': 'wrench'},
            'design': {'color': '#EC4899', 'icon': 'color-swatch'},
            'development': {'color': '#06B6D4', 'icon': 'code'},
            'reading': {'color': '#84CC16', 'icon': 'book-open'},
            'news': {'color': '#F97316', 'icon': 'newspaper'},
            'social': {'color': '#8B5CF6', 'icon': 'users'},
            'shopping': {'color': '#06B6D4', 'icon': 'shopping-bag'},
            'travel': {'color': '#10B981', 'icon': 'globe'},
            'health': {'color': '#EF4444', 'icon': 'heart'},
            'finance': {'color': '#059669', 'icon': 'currency-dollar'},
            'education': {'color': '#7C3AED', 'icon': 'academic-cap'},
            'entertainment': {'color': '#EC4899', 'icon': 'play'},
            'docs': {'color': '#6B7280', 'icon': 'document'},
            'images': {'color': '#F59E0B', 'icon': 'photograph'},
            'videos': {'color': '#DC2626', 'icon': 'video-camera'},
        }
        
        # Check for keyword matches
        for keyword, props in mappings.items():
            if keyword in name_lower:
                return props
        
        # Default
        return {'color': '#6B7280', 'icon': 'folder'}
    
    def _auto_categorize_links(self, folder: Folder, search_terms: str) -> int:
        """Automatically categorize existing links into folder"""
        if not search_terms:
            return 0
        
        # Find potentially matching links
        search_pattern = f'%{search_terms.lower()}%'
        
        candidates = Link.query.filter(
            Link.user_id == self.user_id,
            Link.soft_deleted == False,
            Link.archived_at.is_(None),
            Link.folder_id.is_(None),  # Only unassigned links
            func.lower(Link.title).like(search_pattern) |
            func.lower(Link.original_url).like(search_pattern) |
            func.lower(Link.notes).like(search_pattern)
        ).limit(50).all()  # Limit to prevent mass moves
        
        moved_count = 0
        for link in candidates:
            # Calculate confidence score
            confidence = self._calculate_categorization_confidence(link, search_terms)
            
            # Only auto-move with high confidence
            if confidence > 0.7:
                link.folder_id = folder.id
                moved_count += 1
        
        if moved_count > 0:
            db.session.commit()
            logger.info(f"Auto-categorized {moved_count} links into folder '{folder.name}'")
        
        return moved_count
    
    def _calculate_categorization_confidence(self, link: Link, folder_name: str) -> float:
        """Calculate confidence score for auto-categorization"""
        score = 0.0
        name_lower = folder_name.lower()
        
        # Title match (highest weight)
        if link.title and name_lower in link.title.lower():
            score += 0.5
        
        # URL/domain match
        from app.utils.url import extract_domain
        domain = extract_domain(link.original_url)
        if domain and name_lower in domain.lower():
            score += 0.3
        
        # Notes match
        if link.notes and name_lower in link.notes.lower():
            score += 0.2
        
        return min(1.0, score)
    
    def get_folder_analytics(self, folder_id: int) -> Dict[str, Any]:
        """Get comprehensive folder analytics"""
        folder = Folder.query.filter_by(
            id=folder_id,
            user_id=self.user_id,
            soft_deleted=False
        ).first()
        
        if not folder:
            return {}
        
        # Basic stats
        total_links = Link.query.filter_by(
            folder_id=folder_id,
            user_id=self.user_id,
            soft_deleted=False
        ).count()
        
        active_links = Link.query.filter_by(
            folder_id=folder_id,
            user_id=self.user_id,
            soft_deleted=False,
            archived_at=None
        ).count()
        
        # Link types
        link_types = db.session.query(
            Link.link_type,
            func.count(Link.id).label('count')
        ).filter_by(
            folder_id=folder_id,
            user_id=self.user_id,
            soft_deleted=False
        ).group_by(Link.link_type).all()
        
        # Recent activity
        from datetime import timedelta
        week_ago = datetime.utcnow() - timedelta(days=7)
        recent_links = Link.query.filter(
            Link.folder_id == folder_id,
            Link.user_id == self.user_id,
            Link.soft_deleted == False,
            Link.created_at >= week_ago
        ).count()
        
        # Top domains
        domain_stats = self._get_folder_domain_stats(folder_id)
        
        return {
            'folder_id': folder_id,
            'name': folder.name,
            'total_links': total_links,
            'active_links': active_links,
            'link_types': dict(link_types),
            'recent_additions': recent_links,
            'top_domains': domain_stats,
            'created_at': folder.created_at.isoformat() if folder.created_at else None,
            'last_activity': self._get_last_activity(folder_id)
        }
    
    def _get_folder_domain_stats(self, folder_id: int) -> List[Dict[str, Any]]:
        """Get domain statistics for folder"""
        links = Link.query.filter_by(
            folder_id=folder_id,
            user_id=self.user_id,
            soft_deleted=False
        ).all()
        
        domain_counts = {}
        for link in links:
            from app.utils.url import extract_domain
            domain = extract_domain(link.original_url)
            if domain:
                domain_counts[domain] = domain_counts.get(domain, 0) + 1
        
        # Sort by count
        sorted_domains = sorted(
            domain_counts.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        return [
            {'domain': domain, 'count': count}
            for domain, count in sorted_domains[:10]
        ]
    
    def _get_last_activity(self, folder_id: int) -> Optional[str]:
        """Get timestamp of last activity in folder"""
        last_link = Link.query.filter_by(
            folder_id=folder_id,
            user_id=self.user_id,
            soft_deleted=False
        ).order_by(desc(Link.updated_at)).first()
        
        if last_link and last_link.updated_at:
            return last_link.updated_at.isoformat()
        
        return None
    
    def suggest_folder_merge(self) -> List[Dict[str, Any]]:
        """Suggest folders that could be merged"""
        folders = Folder.query.filter_by(
            user_id=self.user_id,
            soft_deleted=False
        ).all()
        
        suggestions = []
        
        # Find folders with similar names
        for i, folder1 in enumerate(folders):
            for folder2 in folders[i+1:]:
                similarity = self._calculate_name_similarity(folder1.name, folder2.name)
                
                if similarity > 0.7:  # High similarity threshold
                    # Get link counts
                    count1 = Link.query.filter_by(
                        folder_id=folder1.id,
                        user_id=self.user_id,
                        soft_deleted=False
                    ).count()
                    
                    count2 = Link.query.filter_by(
                        folder_id=folder2.id,
                        user_id=self.user_id,
                        soft_deleted=False
                    ).count()
                    
                    suggestions.append({
                        'folders': [
                            {'id': folder1.id, 'name': folder1.name, 'link_count': count1},
                            {'id': folder2.id, 'name': folder2.name, 'link_count': count2}
                        ],
                        'similarity_score': similarity,
                        'suggested_name': folder1.name if count1 >= count2 else folder2.name,
                        'total_links': count1 + count2
                    })
        
        return sorted(suggestions, key=lambda x: x['similarity_score'], reverse=True)[:5]
    
    def _calculate_name_similarity(self, name1: str, name2: str) -> float:
        """Calculate similarity between folder names"""
        from difflib import SequenceMatcher
        return SequenceMatcher(None, name1.lower(), name2.lower()).ratio()
    
    def bulk_organize_links(self, organization_rules: List[Dict[str, Any]]) -> Dict[str, int]:
        """Bulk organize links based on rules"""
        results = {'moved': 0, 'errors': 0}
        
        for rule in organization_rules:
            try:
                rule_type = rule.get('type')
                
                if rule_type == 'domain':
                    moved = self._organize_by_domain(rule)
                    results['moved'] += moved
                    
                elif rule_type == 'keyword':
                    moved = self._organize_by_keyword(rule)
                    results['moved'] += moved
                    
                elif rule_type == 'date':
                    moved = self._organize_by_date(rule)
                    results['moved'] += moved
                    
            except Exception as e:
                logger.error(f"Error processing organization rule: {e}")
                results['errors'] += 1
        
        db.session.commit()
        self._clear_cache()
        
        return results
    
    def _organize_by_domain(self, rule: Dict[str, Any]) -> int:
        """Organize links by domain"""
        domain = rule.get('domain')
        target_folder_id = rule.get('target_folder_id')
        
        if not domain or not target_folder_id:
            return 0
        
        links = Link.query.filter(
            Link.user_id == self.user_id,
            Link.soft_deleted == False,
            Link.folder_id.is_(None),  # Only unassigned
            func.lower(Link.original_url).like(f'%{domain.lower()}%')
        ).all()
        
        moved = 0
        for link in links:
            from app.utils.url import extract_domain
            if extract_domain(link.original_url) == domain:
                link.folder_id = target_folder_id
                moved += 1
        
        return moved
    
    def _organize_by_keyword(self, rule: Dict[str, Any]) -> int:
        """Organize links by keyword"""
        keyword = rule.get('keyword', '').lower()
        target_folder_id = rule.get('target_folder_id')
        
        if not keyword or not target_folder_id:
            return 0
        
        search_pattern = f'%{keyword}%'
        links = Link.query.filter(
            Link.user_id == self.user_id,
            Link.soft_deleted == False,
            Link.folder_id.is_(None),
            func.lower(Link.title).like(search_pattern) |
            func.lower(Link.notes).like(search_pattern)
        ).all()
        
        for link in links:
            link.folder_id = target_folder_id
        
        return len(links)
    
    def _organize_by_date(self, rule: Dict[str, Any]) -> int:
        """Organize links by creation date"""
        date_range = rule.get('date_range')  # e.g., 'this_month', 'last_week'
        target_folder_id = rule.get('target_folder_id')
        
        if not date_range or not target_folder_id:
            return 0
        
        # Calculate date filter
        now = datetime.utcnow()
        if date_range == 'this_month':
            start_date = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
        elif date_range == 'last_week':
            from datetime import timedelta
            start_date = now - timedelta(days=7)
        else:
            return 0
        
        links = Link.query.filter(
            Link.user_id == self.user_id,
            Link.soft_deleted == False,
            Link.folder_id.is_(None),
            Link.created_at >= start_date
        ).all()
        
        for link in links:
            link.folder_id = target_folder_id
        
        return len(links)
    
    def _clear_cache(self):
        """Clear folder-related cache"""
        if redis_client.available:
            cache_keys = [
                f"{self.cache_key}:tree",
                f"{self.cache_key}:stats",
                f"{self.cache_key}:structure"
            ]
            for key in cache_keys:
                redis_client.delete(key)

def serialize_folder(folder: Folder, include_counts: bool = False, include_analytics: bool = False) -> Dict[str, Any]:
    """Enhanced folder serialization"""
    data = {
        'id': folder.id,
        'name': folder.name,
        'color': folder.color,
        'icon': folder.icon,
        'position': folder.position,
        'parent_id': folder.parent_id,
        'pinned': folder.pinned,
        'created_at': folder.created_at.isoformat() if folder.created_at else None,
        'updated_at': folder.updated_at.isoformat() if folder.updated_at else None
    }
    
    if include_counts:
        data['link_count'] = Link.query.filter_by(
            folder_id=folder.id,
            user_id=folder.user_id,
            soft_deleted=False,
            archived_at=None
        ).count()
        
        data['total_link_count'] = Link.query.filter_by(
            folder_id=folder.id,
            user_id=folder.user_id,
            soft_deleted=False
        ).count()
    
    if include_analytics:
        manager = SmartFolderManager(folder.user_id)
        data['analytics'] = manager.get_folder_analytics(folder.id)
    
    return data

def serialize_folders(folders: List[Folder], include_counts: bool = False) -> List[Dict[str, Any]]:
    """Serialize multiple folders"""
    return [serialize_folder(folder, include_counts) for folder in folders]

# Update existing functions
def create_folder(user_id: str, data: Dict[str, Any]) -> Optional[Folder]:
    """Enhanced folder creation"""
    manager = SmartFolderManager(user_id)
    folder, error = manager.create_smart_folder(data)
    return folder

def get_user_folders(user_id: str) -> List[Folder]:
    """Get user folders with caching"""
    cache_key = f"folders:{user_id}:list"
    
    if redis_client.available:
        cached = redis_client.get(cache_key)
        if cached:
            try:
                folder_ids = json.loads(cached)
                return Folder.query.filter(
                    Folder.id.in_(folder_ids),
                    Folder.user_id == user_id,
                    Folder.soft_deleted == False
                ).order_by(Folder.position, Folder.created_at).all()
            except (json.JSONDecodeError, TypeError):
                pass
    
    folders = Folder.query.filter_by(
        user_id=user_id,
        soft_deleted=False
    ).order_by(Folder.position, Folder.created_at).all()
    
    # Cache folder IDs
    if redis_client.available:
        folder_ids = [f.id for f in folders]
        redis_client.setex(cache_key, 300, json.dumps(folder_ids))
    
    return folders

def get_folder_with_counts(user_id: str) -> List[Dict[str, Any]]:
    """Enhanced folder listing with counts"""
    cache_key = f"folders:{user_id}:with_counts"
    
def update_folder(user_id: str, folder_id: int, data: Dict[str, Any]) -> Optional[Folder]:
    """Update folder (backward compatibility wrapper)"""
    folder = Folder.query.filter_by(
        id=folder_id,
        user_id=user_id,
        soft_deleted=False
    ).first()
    
    if not folder:
        return None
    
    if 'name' in data:
        name = data['name'].strip()
        if not name:
            return None
        
        existing = Folder.query.filter(
            Folder.user_id == user_id,
            Folder.name == name,
            Folder.id != folder_id,
            Folder.soft_deleted == False
        ).first()
        
        if existing:
            return None
        
        folder.name = name
    
    if 'color' in data:
        folder.color = data['color']
    
    if 'icon' in data:
        folder.icon = data['icon']
    
    if 'position' in data:
        folder.position = data['position']
    
    if 'pinned' in data:
        folder.pinned = bool(data['pinned'])
    
    folder.updated_at = datetime.utcnow()
    db.session.commit()
    return folder

def soft_delete_folder(user_id: str, folder_id: int) -> bool:
    """Soft delete folder (backward compatibility)"""
    folder = Folder.query.filter_by(
        id=folder_id,
        user_id=user_id,
        soft_deleted=False
    ).first()
    
    if not folder:
        return False
    
    # Move child folders to root level
    child_folders = Folder.query.filter_by(
        parent_id=folder_id,
        user_id=user_id,
        soft_deleted=False
    ).all()
    
    for child in child_folders:
        child.parent_id = folder.parent_id
    
    # Unassign links from folder
    Link.query.filter_by(
        folder_id=folder_id,
        user_id=user_id
    ).update({'folder_id': None})
    
    folder.soft_deleted = True
    folder.updated_at = datetime.utcnow()
    db.session.commit()
    return True

def restore_folder(user_id: str, folder_id: int) -> Optional[Folder]:
    """Restore soft deleted folder (backward compatibility)"""
    folder = Folder.query.filter_by(
        id=folder_id,
        user_id=user_id,
        soft_deleted=True
    ).first()
    
    if not folder:
        return None
    
    folder.soft_deleted = False
    folder.updated_at = datetime.utcnow()
    db.session.commit()
    return folder




16. # server/app/folders/routes.py

from flask import request, g
from app.folders import folders_bp
from app.auth.middleware import require_auth
from app.responses import success_response, error_response
from app.folders.service import (
    SmartFolderManager, create_folder, get_user_folders, 
    update_folder, soft_delete_folder, restore_folder,
    serialize_folder
)
from app.folders.tree import get_folder_tree, move_folder

@folders_bp.route('', methods=['POST'])
@require_auth
def create():
    """Create a new folder with smart features"""
    data = request.get_json()
    if not data or not data.get('name'):
        return error_response('name is required', 400)
    
    manager = SmartFolderManager(g.current_user.id)
    folder, error = manager.create_smart_folder(data)
    
    if error:
        return error_response(error, 400)
    
    return success_response({
        'folder': serialize_folder(folder, include_counts=True)
    }, status=201)

@folders_bp.route('', methods=['GET'])
@require_auth
def list_folders():
    """List user folders with enhanced data"""
    include_analytics = request.args.get('include_analytics', 'false').lower() == 'true'
    view = request.args.get('view', 'list')  # 'list' or 'tree'
    
    if view == 'tree':
        folders = get_folder_tree(g.current_user.id, include_counts=True)
        return success_response({'folders': folders})
    
    folders = get_user_folders(g.current_user.id)
    
    serialized_folders = []
    for folder in folders:
        folder_data = serialize_folder(
            folder, 
            include_counts=True, 
            include_analytics=include_analytics
        )
        serialized_folders.append(folder_data)
    
    return success_response({'folders': serialized_folders})

@folders_bp.route('/<int:folder_id>/analytics', methods=['GET'])
@require_auth
def get_analytics(folder_id):
    """Get detailed folder analytics"""
    manager = SmartFolderManager(g.current_user.id)
    analytics = manager.get_folder_analytics(folder_id)
    
    if not analytics:
        return error_response('Folder not found', 404)
    
    return success_response({'analytics': analytics})

@folders_bp.route('/<int:folder_id>/move', methods=['POST'])
@require_auth
def move_folder_endpoint(folder_id):
    """Move folder to different parent"""
    data = request.get_json()
    if not data:
        return error_response('Invalid request body', 400)
    
    new_parent_id = data.get('parent_id')
    
    if not move_folder(g.current_user.id, folder_id, new_parent_id):
        return error_response('Failed to move folder', 400)
    
    return success_response({'message': 'Folder moved successfully'})

@folders_bp.route('/bulk-organize', methods=['POST'])
@require_auth
def bulk_organize():
    """Bulk organize links using rules"""
    data = request.get_json()
    if not data or not data.get('rules'):
        return error_response('Organization rules are required', 400)
    
    rules = data.get('rules', [])
    if not isinstance(rules, list) or len(rules) > 20:
        return error_response('Invalid rules (max 20 allowed)', 400)
    
    manager = SmartFolderManager(g.current_user.id)
    results = manager.bulk_organize_links(rules)
    
    return success_response({
        'results': results,
        'message': f"Organized {results['moved']} links with {results['errors']} errors"
    })

@folders_bp.route('/merge-suggestions', methods=['GET'])
@require_auth
def get_merge_suggestions():
    """Get suggestions for folder merging"""
    manager = SmartFolderManager(g.current_user.id)
    suggestions = manager.suggest_folder_merge()
    
    return success_response({'suggestions': suggestions})

@folders_bp.route('/<int:folder_id>/pin', methods=['POST'])
@require_auth
def pin_folder(folder_id):
    """Pin/unpin folder"""
    folder = Folder.query.filter_by(
        id=folder_id,
        user_id=g.current_user.id,
        soft_deleted=False
    ).first()
    
    if not folder:
        return error_response('Folder not found', 404)
    
    folder.pinned = not folder.pinned
    from app.extensions import db
    db.session.commit()
    
    action = 'pinned' if folder.pinned else 'unpinned'
    return success_response({
        'message': f'Folder {action} successfully',
        'pinned': folder.pinned
    })

@folders_bp.route('/<int:folder_id>', methods=['PUT'])
@require_auth
def update(folder_id):
    """Update folder with validation"""
    data = request.get_json()
    if not data:
        return error_response('Invalid request body', 400)
    
    folder = update_folder(g.current_user.id, folder_id, data)
    if not folder:
        return error_response('Folder not found or name already exists', 404)
    
    return success_response({
        'folder': serialize_folder(folder, include_counts=True)
    })

@folders_bp.route('/<int:folder_id>', methods=['DELETE'])
@require_auth
def delete(folder_id):
    """Soft delete folder"""
    if not soft_delete_folder(g.current_user.id, folder_id):
        return error_response('Folder not found', 404)
    
    return success_response(message='Folder deleted')

@folders_bp.route('/<int:folder_id>/restore', methods=['POST'])
@require_auth
def restore(folder_id):
    """Restore soft deleted folder"""
    folder = restore_folder(g.current_user.id, folder_id)
    if not folder:
        return error_response('Folder not found', 404)
    
    return success_response({
        'folder': serialize_folder(folder, include_counts=True)
    })




17. # server/app/links/service.py

from datetime import datetime
from typing import Optional, Dict, Any, Tuple
from app.extensions import db
from app.models.link import Link
from app.links.queries import get_link_for_user
from app.links.duplicate import check_duplicate
from app.utils.slug import generate_unique_slug, is_slug_available
import logging

logger = logging.getLogger(__name__)

def create_link(user_id: str, data: Dict[str, Any]) -> Tuple[Optional[Link], Optional[Dict]]:
    """Enhanced link creation with metadata extraction and validation"""
    original_url = data.get('original_url', '').strip()
    if not original_url:
        return None, {'error': 'original_url is required'}

    # Validate URL format
    if not _validate_url_format(original_url):
        return None, {'error': 'Invalid URL format'}

    link_type = data.get('link_type', 'saved')
    if link_type not in ('saved', 'shortened'):
        return None, {'error': 'link_type must be saved or shortened'}

    # Check for duplicates
    duplicate = check_duplicate(user_id, original_url)

    # Handle short link slug
    slug = None
    if link_type == 'shortened':
        slug = data.get('slug')
        if slug:
            slug = slug.strip().lower()
            if not is_slug_available(slug):
                return None, {'error': 'Slug already taken'}
        else:
            slug = generate_unique_slug()
    
    # Validate folder if provided
    folder_id = data.get('folder_id')
    if folder_id is not None:
        from app.models import Folder
        folder = Folder.query.filter_by(
            id=folder_id,
            user_id=user_id,
            soft_deleted=False
        ).first()
        
        if not folder:
            return None, {'error': 'Folder not found'}

    # Handle expiration for short links
    expires_at = None
    if link_type == 'shortened' and data.get('expires_at'):
        expires_at, error = _parse_expiration(data['expires_at'])
        if error:
            return None, {'error': error}

    # Get title and notes
    title = data.get('title', '').strip() or None
    notes = data.get('notes', '').strip() or None

    # Prepare metadata
    metadata = data.get('metadata', {})
    
    # UTM parameters for short links
    if link_type == 'shortened' and data.get('utm_params'):
        original_url = _append_utm_parameters(original_url, data['utm_params'])
        metadata['utm_params'] = data['utm_params']

    # Password protection for short links
    password_hash = None
    if link_type == 'shortened' and data.get('password'):
        password_hash = _hash_password(data['password'])
        metadata['password_protected'] = True

    # Click limit for short links
    if link_type == 'shortened' and data.get('click_limit'):
        metadata['click_limit'] = data['click_limit']

    # Create link
    link = Link(
        user_id=user_id,
        folder_id=folder_id,
        original_url=original_url,
        link_type=link_type,
        slug=slug,
        title=title,
        notes=notes,
        expires_at=expires_at,
        is_active=True,
        pinned=data.get('pinned', False),
        starred=data.get('starred', False),
        soft_deleted=False,
        click_count=0,
        metadata_=metadata,
        password_hash=password_hash
    )

    db.session.add(link)
    db.session.flush()
    
    # Handle tags
    tag_ids = data.get('tag_ids', [])
    if tag_ids:
        from app.links.tagging import add_tags_to_link
        add_tags_to_link(user_id, link.id, tag_ids)
    
    # Queue for metadata extraction if no title and is saved link
    if not title and link_type == 'saved':
        _queue_metadata_extraction(link.id)
    
    db.session.commit()

    # Prepare response
    result = {'link': link}
    if duplicate:
        result['duplicate_warning'] = duplicate

    return link, result if duplicate else None

def update_link(user_id: str, link_id: int, data: Dict[str, Any]) -> Tuple[Optional[Link], Optional[str]]:
    """Enhanced link update with metadata refresh option"""
    link = get_link_for_user(link_id, user_id)
    if not link:
        return None, 'Link not found'

    # Update basic fields
    if 'title' in data:
        new_title = data['title'].strip() if data['title'] else None
        link.title = new_title

    if 'notes' in data:
        link.notes = data['notes'].strip() if data['notes'] else None

    if 'original_url' in data:
        url = data['original_url'].strip()
        if not url:
            return None, 'original_url cannot be empty'
        if not _validate_url_format(url):
            return None, 'Invalid URL format'
        
        # If URL changed, queue for metadata refresh
        if url != link.original_url:
            link.original_url = url
            _queue_metadata_extraction(link.id)

    # Update status fields
    if 'pinned' in data:
        link.pinned = bool(data['pinned'])
        if link.pinned:
            link.pinned_at = datetime.utcnow()
        else:
            link.pinned_at = None

    if 'starred' in data:
        link.starred = bool(data['starred'])

    if 'frequently_used' in data:
        link.frequently_used = bool(data['frequently_used'])

    # Short link specific updates
    if link.link_type == 'shortened':
        if 'slug' in data:
            new_slug = data['slug'].strip().lower()
            if new_slug != link.slug and not is_slug_available(new_slug):
                return None, 'Slug already taken'
            link.slug = new_slug

        if 'expires_at' in data:
            if data['expires_at']:
                expires_at, error = _parse_expiration(data['expires_at'])
                if error:
                    return None, error
                link.expires_at = expires_at
            else:
                link.expires_at = None

        # Update UTM parameters
        if 'utm_params' in data:
            utm_params = data['utm_params']
            metadata = link.metadata_ or {}
            metadata['utm_params'] = utm_params
            link.metadata_ = metadata
            
            # Update URL with new UTM params if they exist
            if utm_params:
                base_url = link.original_url.split('?')[0]
                link.original_url = _append_utm_parameters(base_url, utm_params)

    # Update folder
    if 'folder_id' in data:
        folder_id = data['folder_id']
        if folder_id is not None:
            from app.models import Folder
            folder = Folder.query.filter_by(
                id=folder_id,
                user_id=user_id,
                soft_deleted=False
            ).first()
            if not folder:
                return None, 'Folder not found'
        link.folder_id = folder_id

    # Refresh metadata if requested
    if data.get('refresh_metadata'):
        _queue_metadata_extraction(link.id)

    link.updated_at = datetime.utcnow()
    db.session.commit()
    return link, None

def pin_link(user_id: str, link_id: int) -> Tuple[bool, Optional[str]]:
    """Pin a link for quick access"""
    link = get_link_for_user(link_id, user_id)
    if not link:
        return False, 'Link not found'

    link.pinned = True
    link.pinned_at = datetime.utcnow()
    link.updated_at = datetime.utcnow()
    db.session.commit()
    return True, None

def unpin_link(user_id: str, link_id: int) -> Tuple[bool, Optional[str]]:
    """Unpin a link"""
    link = get_link_for_user(link_id, user_id)
    if not link:
        return False, 'Link not found'

    link.pinned = False
    link.pinned_at = None
    link.updated_at = datetime.utcnow()
    db.session.commit()
    return True, None

def star_link(user_id: str, link_id: int) -> Tuple[bool, Optional[str]]:
    """Star a link (mark as favorite)"""
    link = get_link_for_user(link_id, user_id)
    if not link:
        return False, 'Link not found'

    link.starred = True
    link.updated_at = datetime.utcnow()
    db.session.commit()
    return True, None

def unstar_link(user_id: str, link_id: int) -> Tuple[bool, Optional[str]]:
    """Unstar a link"""
    link = get_link_for_user(link_id, user_id)
    if not link:
        return False, 'Link not found'

    link.starred = False
    link.updated_at = datetime.utcnow()
    db.session.commit()
    return True, None

def toggle_frequently_used(user_id: str, link_id: int) -> Tuple[Optional[bool], Optional[str]]:
    """Toggle frequently used status"""
    link = get_link_for_user(link_id, user_id)
    if not link:
        return None, 'Link not found'

    link.frequently_used = not link.frequently_used
    link.updated_at = datetime.utcnow()
    db.session.commit()
    return link.frequently_used, None

def archive_link(user_id: str, link_id: int) -> Tuple[bool, Optional[str]]:
    """Archive a link"""
    link = get_link_for_user(link_id, user_id)
    if not link:
        return False, 'Link not found'

    link.archived_at = datetime.utcnow()
    link.pinned = False  # Unpin when archiving
    link.pinned_at = None
    link.updated_at = datetime.utcnow()
    db.session.commit()
    return True, None

def restore_link(user_id: str, link_id: int) -> Tuple[bool, Optional[str]]:
    """Restore an archived link"""
    link = get_link_for_user(link_id, user_id)
    if not link:
        return False, 'Link not found'

    link.archived_at = None
    link.updated_at = datetime.utcnow()
    db.session.commit()
    return True, None

def toggle_active(user_id: str, link_id: int) -> Tuple[Optional[bool], Optional[str]]:
    """Toggle link active status (mainly for short links)"""
    link = get_link_for_user(link_id, user_id)
    if not link:
        return None, 'Link not found'

    link.is_active = not link.is_active
    link.updated_at = datetime.utcnow()
    db.session.commit()
    return link.is_active, None

def soft_delete_link(user_id: str, link_id: int) -> Tuple[bool, Optional[str]]:
    """Soft delete a link"""
    link = get_link_for_user(link_id, user_id)
    if not link:
        return False, 'Link not found'

    # Remove from any tags
    from app.models import LinkTag
    LinkTag.query.filter_by(link_id=link_id, user_id=user_id).delete()

    link.soft_deleted = True
    link.updated_at = datetime.utcnow()
    db.session.commit()
    return True, None

def mark_link_accessed(user_id: str, link_id: int) -> bool:
    """Mark a link as accessed for frequency tracking"""
    link = get_link_for_user(link_id, user_id)
    if not link:
        return False

    # Update access metrics
    link.click_count += 1
    link.updated_at = datetime.utcnow()
    
    # Mark as frequently used if accessed multiple times
    if link.click_count >= 3:
        link.frequently_used = True

    db.session.commit()
    return True

def bulk_update_links(user_id: str, link_ids: list, updates: Dict[str, Any]) -> Dict[str, int]:
    """Bulk update multiple links"""
    results = {'updated': 0, 'errors': 0}
    
    if not link_ids or len(link_ids) > 100:  # Limit bulk operations
        return results

    try:
        # Get all links at once
        links = Link.query.filter(
            Link.id.in_(link_ids),
            Link.user_id == user_id,
            Link.soft_deleted == False
        ).all()

        for link in links:
            try:
                # Apply updates
                if 'pinned' in updates:
                    link.pinned = bool(updates['pinned'])
                    if link.pinned:
                        link.pinned_at = datetime.utcnow()
                    else:
                        link.pinned_at = None

                if 'starred' in updates:
                    link.starred = bool(updates['starred'])

                if 'folder_id' in updates:
                    # Validate folder exists
                    folder_id = updates['folder_id']
                    if folder_id is not None:
                        from app.models import Folder
                        folder_exists = Folder.query.filter_by(
                            id=folder_id,
                            user_id=user_id,
                            soft_deleted=False
                        ).first()
                        if not folder_exists:
                            results['errors'] += 1
                            continue
                    link.folder_id = folder_id

                if 'archived' in updates:
                    if updates['archived']:
                        link.archived_at = datetime.utcnow()
                        link.pinned = False
                        link.pinned_at = None
                    else:
                        link.archived_at = None

                link.updated_at = datetime.utcnow()
                results['updated'] += 1

            except Exception as e:
                logger.error(f"Error updating link {link.id}: {e}")
                results['errors'] += 1

        db.session.commit()

    except Exception as e:
        logger.error(f"Error in bulk update: {e}")
        db.session.rollback()
        results['errors'] = len(link_ids)

    return results

def get_link_statistics(user_id: str) -> Dict[str, Any]:
    """Get comprehensive link statistics for user"""
    from app.models import Link, Folder, Tag, LinkTag
    from sqlalchemy import func
    from datetime import timedelta

    # Base query
    base_query = Link.query.filter(
        Link.user_id == user_id,
        Link.soft_deleted == False
    )

    # Basic counts
    total_links = base_query.count()
    active_links = base_query.filter(
        Link.archived_at.is_(None),
        Link.is_active == True
    ).count()

    saved_links = base_query.filter(Link.link_type == 'saved').count()
    short_links = base_query.filter(Link.link_type == 'shortened').count()

    # Status counts
    pinned_count = base_query.filter(Link.pinned == True).count()
    starred_count = base_query.filter(Link.starred == True).count()
    frequently_used_count = base_query.filter(Link.frequently_used == True).count()
    archived_count = base_query.filter(Link.archived_at.isnot(None)).count()

    # Time-based stats
    now = datetime.utcnow()
    week_ago = now - timedelta(days=7)
    month_ago = now - timedelta(days=30)

    recent_links = base_query.filter(Link.created_at >= week_ago).count()
    monthly_links = base_query.filter(Link.created_at >= month_ago).count()

    # Short link specific stats
    short_link_query = base_query.filter(Link.link_type == 'shortened')
    total_clicks = short_link_query.with_entities(
        func.sum(Link.click_count)
    ).scalar() or 0

    expired_short_links = short_link_query.filter(
        Link.expires_at.isnot(None),
        Link.expires_at <= now
    ).count()

    # Organization stats
    unassigned_links = base_query.filter(
        Link.folder_id.is_(None),
        Link.archived_at.is_(None)
    ).count()

    tagged_links = base_query.join(LinkTag).distinct().count()

    return {
        'overview': {
            'total_links': total_links,
            'active_links': active_links,
            'saved_links': saved_links,
            'short_links': short_links,
            'total_clicks': total_clicks
        },
        'status': {
            'pinned': pinned_count,
            'starred': starred_count,
            'frequently_used': frequently_used_count,
            'archived': archived_count
        },
        'time_based': {
            'recent_week': recent_links,
            'recent_month': monthly_links
        },
        'organization': {
            'unassigned': unassigned_links,
            'tagged': tagged_links,
            'organization_score': ((total_links - unassigned_links) / max(total_links, 1)) * 100
        },
        'short_links': {
            'total': short_links,
            'total_clicks': total_clicks,
            'expired': expired_short_links,
            'avg_clicks': total_clicks / max(short_links, 1)
        }
    }

# Helper functions

def _validate_url_format(url: str) -> bool:
    """Validate URL format"""
    import re
    url_pattern = re.compile(
        r'^https?://'  # http:// or https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domain
        r'localhost|'  # localhost
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # IP
        r'(?::\d+)?'  # optional port
        r'(?:/?|[/?]\S+)$', re.IGNORECASE
    )
    return bool(url_pattern.match(url))

def _parse_expiration(expiry_input: str) -> Tuple[Optional[datetime], Optional[str]]:
    """Parse expiration date/time input"""
    try:
        # ISO format
        if 'T' in expiry_input or 'Z' in expiry_input:
            return datetime.fromisoformat(expiry_input.replace('Z', '+00:00')), None
        
        # Relative formats (e.g., "7d", "24h", "1w")
        import re
        match = re.match(r'^(\d+)([hdwmy])$', expiry_input.lower())
        if match:
            amount, unit = int(match.group(1)), match.group(2)
            
            from datetime import timedelta
            if unit == 'h':
                delta = timedelta(hours=amount)
            elif unit == 'd':
                delta = timedelta(days=amount)
            elif unit == 'w':
                delta = timedelta(weeks=amount)
            elif unit == 'm':
                delta = timedelta(days=amount * 30)
            elif unit == 'y':
                delta = timedelta(days=amount * 365)
            else:
                return None, 'Invalid time unit'
            
            expires_at = datetime.utcnow() + delta
            return expires_at, None
        
        return None, 'Invalid expiration format'
        
    except ValueError:
        return None, 'Invalid expiration format'

def _append_utm_parameters(url: str, utm_params: Dict[str, str]) -> str:
    """Append UTM parameters to URL"""
    from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
    
    parsed = urlparse(url)
    query_params = parse_qs(parsed.query)
    
    # Add UTM parameters
    utm_mapping = {
        'source': 'utm_source',
        'medium': 'utm_medium', 
        'campaign': 'utm_campaign',
        'term': 'utm_term',
        'content': 'utm_content'
    }
    
    for key, utm_key in utm_mapping.items():
        if key in utm_params and utm_params[key]:
            query_params[utm_key] = [utm_params[key]]
    
    # Rebuild URL
    new_query = urlencode(query_params, doseq=True)
    return urlunparse(parsed._replace(query=new_query))

def _hash_password(password: str) -> str:
    """Hash password for protection"""
    import hashlib
    return hashlib.sha256(password.encode()).hexdigest()

def _queue_metadata_extraction(link_id: int):
    """Queue link for metadata extraction"""
    try:
        from app.metadata.service import background_processor
        import asyncio
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(background_processor.queue_link_for_processing(link_id))
        loop.close()
    except Exception as e:
        logger.warning(f"Failed to queue link {link_id} for metadata processing: {e}")




18. # server/app/links/routes.py
from flask import request, g
from app.links import links_bp
from app.auth.middleware import require_auth
from app.responses import success_response, error_response
from app.links.service import (
    create_link, update_link, pin_link, unpin_link,
    archive_link, restore_link, toggle_active, soft_delete_link
)
from app.links.duplicate import check_duplicate
from app.links.tagging import move_to_folder, add_tags_to_link, remove_tags_from_link
import logging

logger = logging.getLogger(__name__)


@links_bp.route('', methods=['POST'])
@require_auth
def create():
    data = request.get_json()
    if not data:
        return error_response('Invalid request body', 400)

    link, extra = create_link(g.current_user.id, data)
    if link is None and extra and 'error' in extra:
        return error_response(extra['error'], 400)

    from app.dashboard.service import serialize_link
    response = {'link': serialize_link(link)}

    if extra and 'duplicate_warning' in extra:
        response['duplicate_warning'] = extra['duplicate_warning']

    return success_response(response, status=201)


@links_bp.route('/<int:link_id>', methods=['PUT', 'PATCH'])
@require_auth
def update(link_id):
    data = request.get_json()
    if not data:
        return error_response('Invalid request body', 400)

    link, err = update_link(g.current_user.id, link_id, data)
    if err:
        return error_response(err, 404 if err == 'Link not found' else 400)

    from app.dashboard.service import serialize_link
    return success_response({'link': serialize_link(link)})


@links_bp.route('/<int:link_id>/pin', methods=['POST'])
@require_auth
def pin(link_id):
    ok, err = pin_link(g.current_user.id, link_id)
    if not ok:
        return error_response(err, 404)
    return success_response(message='Link pinned')


@links_bp.route('/<int:link_id>/unpin', methods=['POST'])
@require_auth
def unpin(link_id):
    ok, err = unpin_link(g.current_user.id, link_id)
    if not ok:
        return error_response(err, 404)
    return success_response(message='Link unpinned')


@links_bp.route('/<int:link_id>/archive', methods=['POST'])
@require_auth
def archive(link_id):
    ok, err = archive_link(g.current_user.id, link_id)
    if not ok:
        return error_response(err, 404)
    return success_response(message='Link archived')


@links_bp.route('/<int:link_id>/restore', methods=['POST'])
@require_auth
def restore(link_id):
    ok, err = restore_link(g.current_user.id, link_id)
    if not ok:
        return error_response(err, 404)
    return success_response(message='Link restored')


@links_bp.route('/<int:link_id>/toggle-active', methods=['POST'])
@require_auth
def toggle(link_id):
    new_state, err = toggle_active(g.current_user.id, link_id)
    if err:
        return error_response(err, 404)
    return success_response({'is_active': new_state})


@links_bp.route('/<int:link_id>', methods=['DELETE'])
@require_auth
def delete(link_id):
    ok, err = soft_delete_link(g.current_user.id, link_id)
    if not ok:
        return error_response(err, 404)
    return success_response(message='Link deleted')


@links_bp.route('/check-duplicate', methods=['POST'])
@require_auth
def check_dup():
    data = request.get_json()
    if not data or not data.get('original_url'):
        return error_response('original_url is required', 400)

    result = check_duplicate(g.current_user.id, data['original_url'])
    return success_response({'duplicate': result})


@links_bp.route('/<int:link_id>/move-folder', methods=['POST'])
@require_auth
def move_folder(link_id):
    data = request.get_json()
    if not data:
        return error_response('Invalid request body', 400)
    
    folder_id = data.get('folder_id')
    
    if not move_to_folder(g.current_user.id, link_id, folder_id):
        return error_response('Link or folder not found', 404)
    
    return success_response(message='Link moved')


@links_bp.route('/<int:link_id>/add-tags', methods=['POST'])
@require_auth
def add_tags(link_id):
    data = request.get_json()
    if not data or 'tag_ids' not in data:
        return error_response('tag_ids is required', 400)
    
    tag_ids = data.get('tag_ids', [])
    if not isinstance(tag_ids, list):
        return error_response('tag_ids must be an array', 400)
    
    if not add_tags_to_link(g.current_user.id, link_id, tag_ids):
        return error_response('Link not found', 404)
    
    return success_response(message='Tags added')


@links_bp.route('/<int:link_id>/remove-tags', methods=['POST'])
@require_auth
def remove_tags(link_id):
    data = request.get_json()
    if not data or 'tag_ids' not in data:
        return error_response('tag_ids is required', 400)
    
    tag_ids = data.get('tag_ids', [])
    if not isinstance(tag_ids, list):
        return error_response('tag_ids must be an array', 400)
    
    if not remove_tags_from_link(g.current_user.id, link_id, tag_ids):
        return error_response('Link not found', 404)
    
    return success_response(message='Tags removed')




19. # server/app/tags/service.py
from typing import Optional, List, Dict, Any
from app.extensions import db
from app.models import Tag, LinkTag, Link
import logging

logger = logging.getLogger(__name__)


def create_tag(user_id: str, data: Dict[str, Any]) -> Optional[Tag]:
    name = data.get('name', '').strip().lower()
    if not name:
        return None
    
    existing = Tag.query.filter_by(
        user_id=user_id,
        name=name
    ).first()
    
    if existing:
        return None
    
    tag = Tag(
        user_id=user_id,
        name=name,
        color=data.get('color')
    )
    
    db.session.add(tag)
    db.session.commit()
    return tag


def get_user_tags(user_id: str) -> List[Tag]:
    return Tag.query.filter_by(
        user_id=user_id
    ).order_by(Tag.name).all()


def get_tags_with_counts(user_id: str) -> List[Dict[str, Any]]:
    tags = db.session.query(
        Tag,
        db.func.count(LinkTag.id).label('usage_count')
    ).outerjoin(
        LinkTag,
        db.and_(
            LinkTag.tag_id == Tag.id,
            LinkTag.user_id == user_id
        )
    ).filter(
        Tag.user_id == user_id
    ).group_by(Tag.id).order_by(Tag.name).all()
    
    return [{
        'id': tag.id,
        'name': tag.name,
        'color': tag.color,
        'usage_count': count
    } for tag, count in tags]


def update_tag(user_id: str, tag_id: int, data: Dict[str, Any]) -> Optional[Tag]:
    tag = Tag.query.filter_by(
        id=tag_id,
        user_id=user_id
    ).first()
    
    if not tag:
        return None
    
    if 'name' in data:
        name = data['name'].strip().lower()
        if not name:
            return None
        
        existing = Tag.query.filter(
            Tag.user_id == user_id,
            Tag.name == name,
            Tag.id != tag_id
        ).first()
        
        if existing:
            return None
        
        tag.name = name
    
    if 'color' in data:
        tag.color = data['color']
    
    db.session.commit()
    return tag


def delete_tag(user_id: str, tag_id: int) -> bool:
    tag = Tag.query.filter_by(
        id=tag_id,
        user_id=user_id
    ).first()
    
    if not tag:
        return False
    
    LinkTag.query.filter_by(
        tag_id=tag_id,
        user_id=user_id
    ).delete()
    
    db.session.delete(tag)
    db.session.commit()
    return True




20. # server/app/tags/routes.py
from flask import request, g
from app.tags import tags_bp
from app.auth.middleware import require_auth
from app.responses import success_response, error_response
from app.tags.service import (
    create_tag, get_user_tags, update_tag, delete_tag
)


@tags_bp.route('', methods=['POST'])
@require_auth
def create():
    data = request.get_json()
    if not data or not data.get('name'):
        return error_response('name is required', 400)
    
    tag = create_tag(g.current_user.id, data)
    if not tag:
        return error_response('Tag already exists', 400)
    
    return success_response({
        'tag': {
            'id': tag.id,
            'name': tag.name,
            'color': tag.color
        }
    }, status=201)


@tags_bp.route('', methods=['GET'])
@require_auth
def list_tags():
    tags = get_user_tags(g.current_user.id)
    
    return success_response({
        'tags': [{
            'id': t.id,
            'name': t.name,
            'color': t.color
        } for t in tags]
    })


@tags_bp.route('/<int:tag_id>', methods=['PUT'])
@require_auth
def update(tag_id):
    data = request.get_json()
    if not data:
        return error_response('Invalid request body', 400)
    
    tag = update_tag(g.current_user.id, tag_id, data)
    if not tag:
        return error_response('Tag not found or name already exists', 404)
    
    return success_response({
        'tag': {
            'id': tag.id,
            'name': tag.name,
            'color': tag.color
        }
    })


@tags_bp.route('/<int:tag_id>', methods=['DELETE'])
@require_auth
def delete(tag_id):
    if not delete_tag(g.current_user.id, tag_id):
        return error_response('Tag not found', 404)
    
    return success_response(message='Tag deleted')





21. # server/app/extensions.py
from flask_sqlalchemy import SQLAlchemy
from flask_migrate import Migrate
import redis
import os
import logging

logger = logging.getLogger(__name__)

db = SQLAlchemy()
migrate = Migrate()

class RedisClient:
    """Wrapper for Redis client with graceful degradation"""
    
    def __init__(self):
        self._client = None
        self._available = False
        self._initialize()
    
    def _initialize(self):
        """Initialize Redis connection if URL provided"""
        redis_url = os.environ.get('REDIS_URL')
        if not redis_url:
            logger.warning("REDIS_URL not configured - Redis features disabled")
            return
        
        try:
            # Support both redis:// and rediss:// (TLS)
            self._client = redis.from_url(
                redis_url,
                decode_responses=True,
                socket_connect_timeout=5,
                socket_timeout=5,
                retry_on_timeout=True,
                health_check_interval=30
            )
            # Test connection
            self._client.ping()
            self._available = True
            logger.info("Redis client initialized successfully")
        except Exception as e:
            logger.warning(f"Redis initialization failed: {e}. Redis features will be disabled.")
            self._client = None
            self._available = False
    
    @property
    def available(self):
        """Check if Redis is available"""
        return self._available and self._client is not None
    
    def execute(self, func, *args, **kwargs):
        """Execute Redis command with error handling"""
        if not self.available:
            return None
        
        try:
            return func(*args, **kwargs)
        except (redis.ConnectionError, redis.TimeoutError) as e:
            logger.warning(f"Redis operation failed: {e}")
            self._available = False
            return None
        except Exception as e:
            logger.error(f"Unexpected Redis error: {e}")
            return None
    
    # Proxy methods for common operations
    def get(self, key):
        return self.execute(self._client.get, key) if self.available else None
    
    def set(self, key, value, ex=None):
        return self.execute(self._client.set, key, value, ex=ex) if self.available else False
    
    def setex(self, key, seconds, value):
        return self.execute(self._client.setex, key, seconds, value) if self.available else False
    
    def delete(self, *keys):
        return self.execute(self._client.delete, *keys) if self.available else 0
    
    def incr(self, key):
        return self.execute(self._client.incr, key) if self.available else None
    
    def expire(self, key, seconds):
        return self.execute(self._client.expire, key, seconds) if self.available else False
    
    def ttl(self, key):
        return self.execute(self._client.ttl, key) if self.available else -2
    
    def exists(self, *keys):
        return self.execute(self._client.exists, *keys) if self.available else 0
    
    def ping(self):
        """Test Redis connectivity"""
        if not self._client:
            return False
        
        try:
            self._client.ping()
            self._available = True
            return True
        except:
            self._available = False
            return False

# Initialize Redis client singleton
redis_client = RedisClient()




22. # server/app/auth/middleware.py
from functools import wraps
from flask import request, g
from app.responses import error_response
from app.auth.firebase import verify_id_token, extract_user_info
from app.auth.provisioning import provision_user
from app.auth.sessions import verify_emergency_session
from app.models import User
import logging

logger = logging.getLogger(__name__)

def require_auth(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        auth_header = request.headers.get('Authorization')
        
        if not auth_header:
            return error_response('Authorization header missing', 401)
        
        if not auth_header.startswith('Bearer '):
            return error_response('Invalid authorization header format', 401)
        
        token = auth_header[7:]
        
        try:
            # Try Firebase token first
            decoded_token = verify_id_token(token)
            if decoded_token:
                user_info = extract_user_info(decoded_token)
                logger.info(f"Firebase auth successful for uid: {user_info.get('uid')}")
                
                try:
                    user = provision_user(user_info)
                    g.current_user = user
                    g.auth_source = 'firebase'
                    return f(*args, **kwargs)
                except Exception as e:
                    logger.error(f"User provisioning failed: {e}", exc_info=True)
                    return error_response('Failed to provision user', 500)
            
            # Try emergency session token
            user = verify_emergency_session(token)
            if user:
                g.current_user = user
                g.auth_source = 'emergency'
                return f(*args, **kwargs)
            
            return error_response('Invalid or expired token', 401)
            
        except Exception as e:
            logger.error(f"Auth middleware error: {e}", exc_info=True)
            return error_response('Authentication failed', 500)
    
    return decorated_function